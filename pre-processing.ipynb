{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Package.ipynb\n",
    "\n",
    "a1= pd.read_csv('./raw_data/0520_怡安(brain-link)/digital_raw_rest.csv',header=None)\n",
    "b1= pd.read_csv('./raw_data/0520_怡安(brain-link)/digital_raw_test.csv',header=None)\n",
    "a2= pd.read_csv('./raw_data/0305_陳柏瑋(tgam)/digital_raw_rest.csv',header=None)\n",
    "b2= pd.read_csv('./raw_data/0305_陳柏瑋(tgam)/digital_raw_test.csv',header=None)\n",
    "a3= pd.read_csv('./raw_data/0521_Abin(brain-link)/digital_raw_rest.csv',header=None)\n",
    "b3= pd.read_csv('./raw_data/0521_Abin(brain-link)/digital_raw_test.csv',header=None)\n",
    "a4= pd.read_csv('./raw_data/0521_建智(brain-link)/digital_raw_rest.csv',header=None)\n",
    "b4= pd.read_csv('./raw_data/0521_建智(brain-link)/digital_raw_test.csv',header=None)\n",
    "a5= pd.read_csv('./raw_data/0701_浩洋(brain-link)/digital_raw_rest.csv',header=None)\n",
    "b5= pd.read_csv('./raw_data/0701_浩洋(brain-link)/digital_raw_test.csv',header=None)\n",
    "a6= pd.read_csv('./raw_data/0630_柏勳(brain-link)/digital_raw_rest.csv',header=None)\n",
    "b6= pd.read_csv('./raw_data/0630_柏勳(brain-link)/digital_raw_test.csv',header=None)\n",
    "a7= pd.read_csv('./raw_data/0323am(tgam)/digital_raw_rest.csv',header=None)\n",
    "b7= pd.read_csv('./raw_data/0323am(tgam)/digital_raw_test.csv',header=None)\n",
    "a8= pd.read_csv('./raw_data/0702_嘉逸(brain-link)/digital_raw_rest.csv',header=None)\n",
    "b8= pd.read_csv('./raw_data/0702_嘉逸(brain-link)/digital_raw_test.csv',header=None)\n",
    "a9= pd.read_csv('./raw_data/0330_奕帆(brain-link)/digital_raw_rest.csv',header=None)\n",
    "b9= pd.read_csv('./raw_data/0330_奕帆(brain-link)/digital_raw_test.csv',header=None)\n",
    "a10= pd.read_csv('./raw_data/0827奕帆(tgam)/digital_raw_rest.csv',header=None)\n",
    "b10= pd.read_csv('./raw_data/0827奕帆(tgam)/digital_raw_test.csv',header=None)\n",
    "a11= pd.read_csv('./raw_data/0331_韶恩(brain-link)/digital_raw_rest.csv',header=None)\n",
    "b11= pd.read_csv('./raw_data/0331_韶恩(brain-link)/digital_raw_test.csv',header=None)\n",
    "a12= pd.read_csv('./raw_data/1010雲多(brain-link)/digital_raw_rest.csv',header=None)\n",
    "b12= pd.read_csv('./raw_data/1010雲多(brain-link)/digital_raw_test.csv',header=None)\n",
    "\n",
    "a13= pd.read_csv('./raw_data/0324am(tgam)/digital_raw_rest.csv',header=None)\n",
    "b13= pd.read_csv('./raw_data/0324am(tgam)/digital_raw_test.csv',header=None)\n",
    "a14= pd.read_csv('./raw_data/1012子軒(brain-link)/digital_raw_rest.csv',header=None)\n",
    "b14= pd.read_csv('./raw_data/1012子軒(brain-link)/digital_raw_test.csv',header=None)\n",
    "a15= pd.read_csv('./raw_data/1012仕誠(brain-link)/digital_raw_rest.csv',header=None)\n",
    "b15= pd.read_csv('./raw_data/1012仕誠(brain-link)/digital_raw_test.csv',header=None)\n",
    "a16= pd.read_csv('./raw_data/1012彥誠(brain-link)/digital_raw_rest.csv',header=None)\n",
    "b16= pd.read_csv('./raw_data/1012彥誠(brain-link)/digital_raw_test.csv',header=None)\n",
    "a17= pd.read_csv('./raw_data/0323pm(tgam)/digital_raw_rest.csv',header=None)\n",
    "b17= pd.read_csv('./raw_data/0323pm(tgam)/digital_raw_test.csv',header=None)\n",
    "\n",
    "a18= pd.read_csv('./raw_data/1012維凡(brain-link)/digital_raw_rest.csv',header=None)\n",
    "b18= pd.read_csv('./raw_data/1012維凡(brain-link)/digital_raw_test.csv',header=None)\n",
    "a19= pd.read_csv('./raw_data/1012韶恩(brain-link)/digital_raw_rest.csv',header=None)\n",
    "b19= pd.read_csv('./raw_data/1012韶恩(brain-link)/digital_raw_test.csv',header=None)\n",
    "a20= pd.read_csv('./raw_data/1013文譯(brain-link)/digital_raw_rest.csv',header=None)\n",
    "b20= pd.read_csv('./raw_data/1013文譯(brain-link)/digital_raw_test.csv',header=None)\n",
    "a21= pd.read_csv('./raw_data/1013奕帆(brain-link)/digital_raw_rest.csv',header=None)\n",
    "b21= pd.read_csv('./raw_data/1013奕帆(brain-link)/digital_raw_test.csv',header=None)\n",
    "a22= pd.read_csv('./raw_data/1014秉諺(brain-link)/digital_raw_rest.csv',header=None)\n",
    "b22= pd.read_csv('./raw_data/1014秉諺(brain-link)/digital_raw_test.csv',header=None)\n",
    "a23= pd.read_csv('./raw_data/0407am(brain-link)/digital_raw_rest.csv',header=None)\n",
    "b23= pd.read_csv('./raw_data/0407am(brain-link)/digital_raw_test.csv',header=None)\n",
    "a24= pd.read_csv('./raw_data/0408am(brain-link)/digital_raw_rest.csv',header=None)\n",
    "b24= pd.read_csv('./raw_data/0408am(brain-link)/digital_raw_test.csv',header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw data convert  to Physical value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 將收集到的raw data轉化為uV\n",
    "2. 將前三十秒鐘(512*30)的資料做移除，減少雜訊\n",
    "3. raw data為10分鐘減去30秒，最後資料長度為570秒"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest1=a1[15360:]*900/4096\n",
    "test1=b1[15360:]*900/4096\n",
    "rest2=a2[15360:]*900/4096\n",
    "test2=b2[15360:]*900/4096\n",
    "rest3=a3[15360:]*900/4096\n",
    "test3=b3[15360:]*900/4096\n",
    "rest4=a4[15360:]*900/4096\n",
    "test4=b4[15360:]*900/4096\n",
    "test5=b5[15360:]*900/4096\n",
    "rest5=a5[15360:len(test5)+15360]*900/4096\n",
    "rest6=a6[15360:]*900/4096\n",
    "test6=b6[15360:]*900/4096\n",
    "rest7=a7[15360:]*900/4096\n",
    "test7=b7[15360:]*900/4096\n",
    "rest8=a8[15360:]*900/4096\n",
    "test8=b8[15360:]*900/4096\n",
    "rest9=a9[15360:]*900/4096\n",
    "test9=b9[15360:]*900/4096\n",
    "rest10=a10[15360:]*900/4096\n",
    "test10=b10[15360:]*900/4096\n",
    "rest11=a11[15360:]*900/4096\n",
    "test11=b11[15360:]*900/4096\n",
    "rest12=a12[15360:]*900/4096\n",
    "test12=b12[15360:]*900/4096\n",
    "rest13=a13[15360:]*900/4096\n",
    "test13=b13[15360:]*900/4096\n",
    "rest14=a14[15360:]*900/4096\n",
    "test14=b14[15360:]*900/4096\n",
    "rest15=a15[15360:]*900/4096\n",
    "test15=b15[15360:]*900/4096\n",
    "rest16=a16[15360:]*900/4096\n",
    "test16=b16[15360:]*900/4096\n",
    "rest17=a17[15360:]*900/4096\n",
    "test17=b17[15360:]*900/4096\n",
    "rest18=a18[15360:]*900/4096\n",
    "test18=b18[15360:]*900/4096\n",
    "rest19=a19[15360:]*900/4096\n",
    "test19=b19[15360:]*900/4096\n",
    "rest20=a20[15360:]*900/4096\n",
    "test20=b20[15360:]*900/4096\n",
    "rest21=a21[15360:]*900/4096\n",
    "test21=b21[15360:]*900/4096\n",
    "rest22=a22[15360:]*900/4096\n",
    "test22=b22[15360:]*900/4096\n",
    "rest23=a23[15360:]*900/4096\n",
    "test23=b23[15360:]*900/4096\n",
    "rest24=a24[15360:]*900/4096\n",
    "test24=b24[15360:]*900/4096"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將資料以設定的時間長度(5s)做切割為一個epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch(data,time,Fs):\n",
    "    epochs = []\n",
    "    for i in range(0, len(data), time*Fs):\n",
    "        ep = data[i:i+time*Fs]\n",
    "        epochs.append(ep)\n",
    "        del ep\n",
    "    gc.collect\n",
    "    return epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt=5 #設定為幾秒為一個epoch\n",
    "eph = int(570/tt) \n",
    "\n",
    "rest1_ep = epoch(rest1,tt,512)[:eph]\n",
    "test1_ep = epoch(test1,tt,512)[:eph]\n",
    "rest2_ep = epoch(rest2,tt,512)[:eph]\n",
    "test2_ep = epoch(test2,tt,512)[:eph]\n",
    "rest3_ep = epoch(rest3,tt,512)[:eph]\n",
    "test3_ep = epoch(test3,tt,512)[:eph]\n",
    "rest4_ep = epoch(rest4,tt,512)[:eph]\n",
    "test4_ep = epoch(test4,tt,512)[:eph]\n",
    "rest5_ep = epoch(rest5,tt,512)[:71]\n",
    "test5_ep = epoch(test5,tt,512)[:71]\n",
    "rest6_ep = epoch(rest6,tt,512)[:eph]\n",
    "test6_ep = epoch(test6,tt,512)[:eph]\n",
    "rest7_ep = epoch(rest7,tt,512)[:eph]\n",
    "test7_ep = epoch(test7,tt,512)[:eph]\n",
    "rest8_ep = epoch(rest8,tt,512)[:eph]\n",
    "test8_ep = epoch(test8,tt,512)[:eph]\n",
    "rest9_ep = epoch(rest9,tt,512)[:eph]\n",
    "test9_ep = epoch(test9,tt,512)[:eph]\n",
    "rest10_ep = epoch(rest10,tt,512)[:eph]\n",
    "test10_ep = epoch(test10,tt,512)[:eph]\n",
    "rest11_ep = epoch(rest11,tt,512)[:eph]\n",
    "test11_ep = epoch(test11,tt,512)[:eph]\n",
    "rest12_ep = epoch(rest12,tt,512)[:eph]\n",
    "test12_ep = epoch(test12,tt,512)[:eph]\n",
    "rest13_ep = epoch(rest13,tt,512)[:eph]\n",
    "test13_ep = epoch(test13,tt,512)[:eph]\n",
    "rest14_ep = epoch(rest14,tt,512)[:eph]\n",
    "test14_ep = epoch(test14,tt,512)[:eph]\n",
    "rest15_ep = epoch(rest15,tt,512)[:eph]\n",
    "test15_ep = epoch(test15,tt,512)[:eph]\n",
    "rest16_ep = epoch(rest16,tt,512)[:eph]\n",
    "test16_ep = epoch(test16,tt,512)[:eph]\n",
    "rest17_ep = epoch(rest17,tt,512)[:eph]\n",
    "test17_ep = epoch(test17,tt,512)[:eph]\n",
    "rest18_ep = epoch(rest18,tt,512)[:eph]\n",
    "test18_ep = epoch(test18,tt,512)[:eph]\n",
    "rest19_ep = epoch(rest19,tt,512)[:eph]\n",
    "test19_ep = epoch(test19,tt,512)[:eph]\n",
    "rest20_ep = epoch(rest20,tt,512)[:eph]\n",
    "test20_ep = epoch(test20,tt,512)[:eph]\n",
    "rest21_ep = epoch(rest21,tt,512)[:eph]\n",
    "test21_ep = epoch(test21,tt,512)[:eph]\n",
    "rest22_ep = epoch(rest22,tt,512)[:eph]\n",
    "test22_ep = epoch(test22,tt,512)[:eph]\n",
    "rest23_ep = epoch(rest23,tt,512)[:eph]\n",
    "test23_ep = epoch(test23,tt,512)[:eph]\n",
    "rest24_ep = epoch(rest24,tt,512)[:eph]\n",
    "test24_ep = epoch(test24,tt,512)[:eph]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# epoch_Filter(Butter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將每一個epoch經過Butterworth濾波器分頻和去雜訊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Filter(data,LH_freq):\n",
    "    sos = signal.butter(N=8,Wn=LH_freq,btype='bandpass',output='sos',fs=512.0)\n",
    "    data = signal.sosfilt(sos, x=data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_Filter(data,Fs):\n",
    "    ep_original=[]\n",
    "    ep_Delta=[]\n",
    "    ep_Theta=[]\n",
    "    ep_Alpha=[]\n",
    "    ep_Beta=[]\n",
    "    for i in range(0, len(data)):\n",
    "        \n",
    "        #original\n",
    "        original = Filter(data=data[i],LH_freq=[0.5, 20])\n",
    "        \n",
    "        # 4 frequency bands\n",
    "        Delta = Filter(data=data[i],LH_freq=[0.5, 4])\n",
    "\n",
    "        Theta = Filter(data=data[i],LH_freq=[4, 8])\n",
    "\n",
    "        Alpha = Filter(data=data[i],LH_freq=[8, 13])\n",
    "\n",
    "        Beta = Filter(data=data[i],LH_freq=[13, 20])\n",
    "        \n",
    "        ep_original.append(original)\n",
    "        ep_Delta.append(Delta)\n",
    "        ep_Theta.append(Theta)\n",
    "        ep_Alpha.append(Alpha)\n",
    "        ep_Beta.append(Beta)\n",
    "        del original,Delta,Theta,Alpha,Beta\n",
    "    gc.collect()\n",
    "    return ep_original,ep_Delta,ep_Theta,ep_Alpha,ep_Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r1_ori,r1_del, r1_the, r1_alp, r1_be = epoch_Filter(rest1_ep,512)\n",
    "t1_ori,t1_del, t1_the, t1_alp, t1_be = epoch_Filter(test1_ep,512)\n",
    "r2_ori,r2_del, r2_the, r2_alp, r2_be = epoch_Filter(rest2_ep,512)\n",
    "t2_ori,t2_del, t2_the, t2_alp, t2_be = epoch_Filter(test2_ep,512)\n",
    "r3_ori,r3_del, r3_the, r3_alp, r3_be = epoch_Filter(rest3_ep,512)\n",
    "t3_ori,t3_del, t3_the, t3_alp, t3_be = epoch_Filter(test3_ep,512)\n",
    "r4_ori,r4_del, r4_the, r4_alp, r4_be = epoch_Filter(rest4_ep,512)\n",
    "t4_ori,t4_del, t4_the, t4_alp, t4_be = epoch_Filter(test4_ep,512)\n",
    "r5_ori,r5_del, r5_the, r5_alp, r5_be = epoch_Filter(rest5_ep,512)\n",
    "t5_ori,t5_del, t5_the, t5_alp, t5_be = epoch_Filter(test5_ep,512)\n",
    "r6_ori,r6_del, r6_the, r6_alp, r6_be = epoch_Filter(rest6_ep,512)\n",
    "t6_ori,t6_del, t6_the, t6_alp, t6_be = epoch_Filter(test6_ep,512)\n",
    "r7_ori,r7_del, r7_the, r7_alp, r7_be = epoch_Filter(rest7_ep,512)\n",
    "t7_ori,t7_del, t7_the, t7_alp, t7_be = epoch_Filter(test7_ep,512)\n",
    "r8_ori,r8_del, r8_the, r8_alp, r8_be = epoch_Filter(rest8_ep,512)\n",
    "t8_ori,t8_del, t8_the, t8_alp, t8_be = epoch_Filter(test8_ep,512)\n",
    "r9_ori,r9_del, r9_the, r9_alp, r9_be = epoch_Filter(rest9_ep,512)\n",
    "t9_ori,t9_del, t9_the, t9_alp, t9_be = epoch_Filter(test9_ep,512)\n",
    "r10_ori,r10_del, r10_the, r10_alp, r10_be = epoch_Filter(rest10_ep,512)\n",
    "t10_ori,t10_del, t10_the, t10_alp, t10_be = epoch_Filter(test10_ep,512)\n",
    "r11_ori,r11_del, r11_the, r11_alp, r11_be = epoch_Filter(rest11_ep,512)\n",
    "t11_ori,t11_del, t11_the, t11_alp, t11_be = epoch_Filter(test11_ep,512)\n",
    "r12_ori,r12_del, r12_the, r12_alp, r12_be = epoch_Filter(rest12_ep,512)\n",
    "t12_ori,t12_del, t12_the, t12_alp, t12_be = epoch_Filter(test12_ep,512)\n",
    "r13_ori,r13_del, r13_the, r13_alp, r13_be = epoch_Filter(rest13_ep,512)\n",
    "t13_ori,t13_del, t13_the, t13_alp, t13_be = epoch_Filter(test13_ep,512)\n",
    "r14_ori,r14_del, r14_the, r14_alp, r14_be = epoch_Filter(rest14_ep,512)\n",
    "t14_ori,t14_del, t14_the, t14_alp, t14_be = epoch_Filter(test14_ep,512)\n",
    "r15_ori,r15_del, r15_the, r15_alp, r15_be = epoch_Filter(rest15_ep,512)\n",
    "t15_ori,t15_del, t15_the, t15_alp, t15_be = epoch_Filter(test15_ep,512)\n",
    "r16_ori,r16_del, r16_the, r16_alp, r16_be = epoch_Filter(rest16_ep,512)\n",
    "t16_ori,t16_del, t16_the, t16_alp, t16_be = epoch_Filter(test16_ep,512)\n",
    "r17_ori,r17_del, r17_the, r17_alp, r17_be = epoch_Filter(rest17_ep,512)\n",
    "t17_ori,t17_del, t17_the, t17_alp, t17_be = epoch_Filter(test17_ep,512)\n",
    "r18_ori,r18_del, r18_the, r18_alp, r18_be = epoch_Filter(rest18_ep,512)\n",
    "t18_ori,t18_del, t18_the, t18_alp, t18_be = epoch_Filter(test18_ep,512)\n",
    "r19_ori,r19_del, r19_the, r19_alp, r19_be = epoch_Filter(rest19_ep,512)\n",
    "t19_ori,t19_del, t19_the, t19_alp, t19_be = epoch_Filter(test19_ep,512)\n",
    "r20_ori,r20_del, r20_the, r20_alp, r20_be = epoch_Filter(rest20_ep,512)\n",
    "t20_ori,t20_del, t20_the, t20_alp, t20_be = epoch_Filter(test20_ep,512)\n",
    "r21_ori,r21_del, r21_the, r21_alp, r21_be = epoch_Filter(rest21_ep,512)\n",
    "t21_ori,t21_del, t21_the, t21_alp, t21_be = epoch_Filter(test21_ep,512)\n",
    "r22_ori,r22_del, r22_the, r22_alp, r22_be = epoch_Filter(rest22_ep,512)\n",
    "t22_ori,t22_del, t22_the, t22_alp, t22_be = epoch_Filter(test22_ep,512)\n",
    "r23_ori,r23_del, r23_the, r23_alp, r23_be = epoch_Filter(rest23_ep,512)\n",
    "t23_ori,t23_del, t23_the, t23_alp, t23_be = epoch_Filter(test23_ep,512)\n",
    "r24_ori,r24_del, r24_the, r24_alp, r24_be = epoch_Filter(rest24_ep,512)\n",
    "t24_ori,t24_del, t24_the, t24_alp, t24_be = epoch_Filter(test24_ep,512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將資料從一個人有5種子頻帶資料整合為各頻帶有24個人的資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df(d1,d2,d3,d4,d5,d6,d7,d8,d9,d10,d11,d12,d13,d14,d15,d16,d17,d18,d19,d20,d21,d22,d23,d24):\n",
    "    \n",
    "    num=eph\n",
    "    ll=tt*512\n",
    "    a=pd.DataFrame(np.array(d1).reshape(num,ll))\n",
    "    b=pd.DataFrame(np.array(d2).reshape(num,ll))\n",
    "    c=pd.DataFrame(np.array(d3).reshape(num,ll))\n",
    "    d=pd.DataFrame(np.array(d4).reshape(num,ll))\n",
    "    e=pd.DataFrame(np.array(d5).reshape(71,ll))\n",
    "    f=pd.DataFrame(np.array(d6).reshape(num,ll))\n",
    "    g=pd.DataFrame(np.array(d7).reshape(num,ll))\n",
    "    h=pd.DataFrame(np.array(d8).reshape(num,ll))\n",
    "    i=pd.DataFrame(np.array(d9).reshape(num,ll))\n",
    "    j=pd.DataFrame(np.array(d10).reshape(num,ll))\n",
    "    k=pd.DataFrame(np.array(d11).reshape(num,ll))\n",
    "    l=pd.DataFrame(np.array(d12).reshape(num,ll))\n",
    "    m=pd.DataFrame(np.array(d13).reshape(num,ll))\n",
    "    n=pd.DataFrame(np.array(d14).reshape(num,ll))\n",
    "    o=pd.DataFrame(np.array(d15).reshape(num,ll))\n",
    "    p=pd.DataFrame(np.array(d16).reshape(num,ll))\n",
    "    q=pd.DataFrame(np.array(d17).reshape(num,ll))\n",
    "    r=pd.DataFrame(np.array(d18).reshape(num,ll))\n",
    "    s=pd.DataFrame(np.array(d19).reshape(num,ll))\n",
    "    t=pd.DataFrame(np.array(d20).reshape(num,ll))\n",
    "    u=pd.DataFrame(np.array(d21).reshape(num,ll))\n",
    "    v=pd.DataFrame(np.array(d22).reshape(num,ll))\n",
    "    w=pd.DataFrame(np.array(d23).reshape(num,ll))\n",
    "    x=pd.DataFrame(np.array(d24).reshape(num,ll))\n",
    "    \n",
    "    df=pd.concat([a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x],axis=0).reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "REST_ORI = df(r1_ori,r2_ori,r3_ori,r4_ori,r5_ori,r6_ori,r7_ori,r8_ori,r9_ori,r10_ori,r11_ori,r12_ori,r13_ori,r14_ori,r15_ori,r16_ori,r17_ori,r18_ori,r19_ori,r20_ori,r21_ori,r22_ori,r23_ori,r24_ori)\n",
    "REST_DEL = df(r1_del,r2_del,r3_del,r4_del,r5_del,r6_del,r7_del,r8_del,r9_del,r10_del,r11_del,r12_del,r13_del,r14_del,r15_del,r16_del,r17_del,r18_del,r19_del,r20_del,r21_del,r22_del,r23_del,r24_del)\n",
    "REST_THE = df(r1_the,r2_the,r3_the,r4_del,r5_the,r6_the,r7_the,r8_the,r9_the,r10_the,r11_the,r12_the,r13_the,r14_the,r15_the,r16_the,r17_the,r18_the,r19_the,r20_the,r21_the,r22_the,r23_the,r24_the)\n",
    "REST_ALP = df(r1_alp,r2_alp,r3_alp,r4_alp,r5_alp,r6_alp,r7_alp,r8_alp,r9_alp,r10_alp,r11_alp,r12_alp,r13_alp,r14_alp,r15_alp,r16_alp,r17_alp,r18_alp,r19_alp,r20_alp,r21_alp,r22_alp,r23_alp,r24_alp)\n",
    "REST_BE = df(r1_be,r2_be,r3_be,r4_be,r5_be,r6_be,r7_be,r8_be,r9_be,r10_be,r11_be,r12_be,r13_be,r14_be,r15_be,r16_be,r17_be,r18_be,r19_be,r20_be,r21_be,r22_be,r23_be,r24_be)\n",
    "\n",
    "TEST_ORI = df(t1_ori,t2_ori,t3_ori,t4_ori,t5_ori,t6_ori,t7_ori,t8_ori,t9_ori,t10_ori,t11_ori,t12_ori,t13_ori,t14_ori,t15_ori,t16_ori,t17_ori,t18_ori,t19_ori,t20_ori,t21_ori,t22_ori,t23_ori,t24_ori)\n",
    "TEST_DEL = df(t1_del,t2_del,t3_del,t4_del,t5_del,t6_del,t7_del,t8_del,t9_del,t10_del,t11_del,t12_del,t13_del,t14_del,t15_del,t16_del,t17_del,t18_del,t19_del,t20_del,t21_del,t22_del,t23_del,t24_del)\n",
    "TEST_THE = df(t1_the,t2_the,t3_the,t4_the,t5_the,t6_the,t7_the,t8_the,t9_the,t10_the,t11_the,t12_the,t13_the,t14_the,t15_the,t16_the,t17_the,t18_the,t19_the,t20_the,t21_the,t22_the,t23_the,t24_the)\n",
    "TEST_ALP = df(t1_alp,t2_alp,t3_alp,t4_alp,t5_alp,t6_alp,t7_alp,t8_alp,t9_alp,t10_alp,t11_alp,t12_alp,t13_alp,t14_alp,t15_alp,t16_alp,t17_alp,t18_alp,t19_alp,t20_alp,t21_alp,t22_alp,t23_alp,t24_alp)\n",
    "TEST_BE = df(t1_be,t2_be,t3_be,t4_be,t5_be,t6_be,t7_be,t8_be,t9_be,t10_be,t11_be,t12_be,t13_be,t14_be,t15_be,t16_be,t17_be,t18_be,t19_be,t20_be,t21_be,t22_be,t23_be,t24_be)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5個手刻特徵和12個網路資源(Api)特徵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AutoCorr(data, k=1):\n",
    "\n",
    "    m = np.mean(data)\n",
    "    N = len(data)\n",
    "\n",
    "    res = np.sum([(data[i + k] - m) * (data[i] - m)\n",
    "                  for i in range(N - k)]) / np.sum([(data[i + k] - m)**(2)\n",
    "                                                    for i in range(N - k)])\n",
    "    return res\n",
    "\n",
    "def avg_pow(data,fs,band):\n",
    "    f,p = signal.welch(np.array(data).flatten(),fs=fs,window='hamming')\n",
    "    \n",
    "    if band=='original':\n",
    "        a = p[0:20]\n",
    "        power = np.sum(a)\n",
    "    if band=='delta':\n",
    "        a = p[0:4]\n",
    "        power = np.sum(a)\n",
    "    if band=='theta':\n",
    "        a = p[4:8]\n",
    "        power = np.sum(a)\n",
    "    if band=='alpha':\n",
    "        a = p[8:13]\n",
    "        power = np.sum(a)\n",
    "    if band=='beta':\n",
    "        a = p[13:20]\n",
    "        power = np.sum(a)\n",
    "    return power\n",
    "\n",
    "def Mean_frequency(data, fs):\n",
    "\n",
    "    freq, psd = signal.welch(data, fs)\n",
    "\n",
    "    return np.dot(freq, psd) / sum(psd)\n",
    "\n",
    "\n",
    "def Spect_slope(data, fs):\n",
    "\n",
    "    freq, psd = signal.welch(data, fs)\n",
    "    slope, intercept, r_value, p_value, slope_std_error = stats.linregress(\n",
    "        freq, psd)\n",
    "\n",
    "    return slope\n",
    "\n",
    "def compute_zero_crossings(data, threshold=np.finfo(np.float64).eps):\n",
    "    \n",
    "    _data = data.copy()\n",
    "    # clip 'small' values to 0\n",
    "    _data[np.abs(_data) < threshold] = 0\n",
    "    sgn = np.sign(_data)\n",
    "    # sgn may already contain 0 values (either 'true' zeros or clipped values)\n",
    "    aux = np.diff((sgn).astype(np.int64), axis=-1)\n",
    "    count = np.sum(aux !=0, axis=-1)\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_map(data,fs,band):\n",
    "    \n",
    "    f1=[]\n",
    "    f2=[]\n",
    "    f3=[]\n",
    "    f4=[]\n",
    "    f5=[]\n",
    "    f6=[]\n",
    "    f7=[]\n",
    "    f8=[]\n",
    "    f9=[]\n",
    "    f10=[]\n",
    "    f11=[]\n",
    "    f12=[]\n",
    "    f13=[]\n",
    "    f14=[]\n",
    "    f15=[]\n",
    "    f16=[]\n",
    "    f17=[]\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        #std = univariate.compute_std(np.array(data.iloc[i, :]))\n",
    "        var =univariate.compute_variance(np.array(data.iloc[i, :]))\n",
    "        #skew = univariate.compute_skewness(np.array(data.iloc[i, :]))\n",
    "        #kurt = univariate.compute_kurtosis(np.array(data.iloc[i, :]))\n",
    "        ptp_amp = np.ptp(np.array(data.iloc[i, :]), axis=0)\n",
    "        #zero_cross = compute_zero_crossings(np.array(data.iloc[i, :]))\n",
    "        \n",
    "        sam_ent = sample_entropy(data.iloc[i, :])\n",
    "        perm_ent = perm_entropy(list(data.iloc[i, :]))\n",
    "        spect_ent = spectral_entropy(data.iloc[i, :],fs,method='welch')\n",
    "        svd_ent = svd_entropy(list(data.iloc[i, :]))\n",
    "        dfa = detrended_fluctuation(list(data.iloc[i, :]))\n",
    "        \n",
    "        power = avg_pow(data.iloc[i, :],fs,band)\n",
    "        mf = Mean_frequency(data.iloc[i, :],fs)\n",
    "        slope = Spect_slope(data.iloc[i, :],fs)\n",
    "        \n",
    "        #hjorth_mobility = univariate.compute_hjorth_mobility(np.array(data.iloc[i, :]))\n",
    "        hjorth_complexity = univariate.compute_hjorth_complexity(np.array(data.iloc[i, :]))\n",
    "        \n",
    "        auto_c = AutoCorr(np.array(data.iloc[i, :]))\n",
    "        \n",
    "        #f1.append(std)\n",
    "        f2.append(var)\n",
    "        #f3.append(skew)\n",
    "        #f4.append(kurt)\n",
    "        f5.append(ptp_amp)\n",
    "        #f6.append(zero_cross)\n",
    "        f7.append(sam_ent)\n",
    "        f8.append(perm_ent)\n",
    "        f9.append(spect_ent)\n",
    "        f10.append(svd_ent)\n",
    "        f11.append(dfa)\n",
    "        f12.append(power)\n",
    "        f13.append(mf)\n",
    "        f14.append(slope)\n",
    "        #f15.append(hjorth_mobility)\n",
    "        f16.append(hjorth_complexity)\n",
    "        f17.append(auto_c)\n",
    "\n",
    "    #F1 = pd.DataFrame(f1,columns=['std'])\n",
    "    F2 = pd.DataFrame(f2,columns=['var'])\n",
    "    #F3 = pd.DataFrame(f3,columns=['skew'])\n",
    "    #F4 = pd.DataFrame(f4,columns=['kurt'])\n",
    "    F5 = pd.DataFrame(f5,columns=['ptp_amp'])\n",
    "    #F6 = pd.DataFrame(f6,columns=['zero_cross'])\n",
    "    F7 = pd.DataFrame(f7,columns=['sam_ent'])\n",
    "    F8 = pd.DataFrame(f8,columns=['perm_ent'])\n",
    "    F9 = pd.DataFrame(f9,columns=['spect_ent'])\n",
    "    F10 = pd.DataFrame(f10,columns=['svd_ent'])\n",
    "    F11 = pd.DataFrame(f11,columns=['dfa'])\n",
    "    F12 = pd.DataFrame(f12,columns=['power'])\n",
    "    F13 = pd.DataFrame(f13,columns=['mf'])\n",
    "    F14 = pd.DataFrame(f14,columns=['slope'])\n",
    "    #F15 = pd.DataFrame(f15,columns=['hjorth_mobility'])\n",
    "    F16 = pd.DataFrame(f16,columns=['hjorth_complexity'])\n",
    "    F17 = pd.DataFrame(f17,columns=['auto_c'])\n",
    "\n",
    "    A = pd.concat([F2,F5,F7,F8,F9,F10,F11,F12,F13,F14,F16,F17],axis=1)\n",
    "    \n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "REST_ORI_F = feature_map(REST_ORI,512,band='original')\n",
    "REST_DEL_F = feature_map(REST_DEL,512,band='delta')\n",
    "REST_THE_F = feature_map(REST_THE,512,band='theta')\n",
    "REST_ALP_F = feature_map(REST_ALP,512,band='alpha')\n",
    "REST_BE_F = feature_map(REST_BE,512,band='beta')\n",
    "\n",
    "TEST_ORI_F = feature_map(TEST_ORI,512,band='original')\n",
    "TEST_DEL_F = feature_map(TEST_DEL,512,band='delta')\n",
    "TEST_THE_F = feature_map(TEST_THE,512,band='theta')\n",
    "TEST_ALP_F = feature_map(TEST_ALP,512,band='alpha')\n",
    "TEST_BE_F = feature_map(TEST_BE,512,band='beta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ratio_band"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比例頻帶不僅可以增加特徵數量外，許多研究表明，比例頻帶的測量也是探索神經振蕩的常用方法。(並且不特定於測量功率，也可以反映信號的其他特徵，例如特徵的非週期性。)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "REST_DOR_F = REST_DEL_F / REST_ORI_F\n",
    "REST_DTR_F = REST_DEL_F / REST_THE_F\n",
    "REST_DAR_F = REST_DEL_F / REST_ALP_F\n",
    "REST_DBR_F = REST_DEL_F / REST_BE_F\n",
    "\n",
    "REST_TOR_F = REST_THE_F / REST_ORI_F\n",
    "REST_TAR_F = REST_THE_F / REST_ALP_F\n",
    "REST_TBR_F = REST_THE_F / REST_BE_F\n",
    "\n",
    "REST_AOR_F = REST_ALP_F / REST_ORI_F\n",
    "REST_ABR_F = REST_ALP_F / REST_BE_F\n",
    "\n",
    "REST_BOR_F = REST_BE_F / REST_ORI_F\n",
    "\n",
    "temp0 = pd.concat([REST_ORI_F,REST_DEL_F,REST_THE_F,REST_ALP_F,REST_BE_F,\n",
    "                   REST_DOR_F,REST_DTR_F,REST_DAR_F,REST_DBR_F,\n",
    "                   REST_TOR_F,REST_TAR_F,REST_TBR_F,\n",
    "                   REST_AOR_F,REST_ABR_F,\n",
    "                   REST_BOR_F\n",
    "                  ],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DOR_F = TEST_DEL_F / TEST_ORI_F\n",
    "TEST_DTR_F = TEST_DEL_F / TEST_THE_F\n",
    "TEST_DAR_F = TEST_DEL_F / TEST_ALP_F\n",
    "TEST_DBR_F = TEST_DEL_F / TEST_BE_F\n",
    "\n",
    "TEST_TOR_F = TEST_THE_F / TEST_ORI_F\n",
    "TEST_TAR_F = TEST_THE_F / TEST_ALP_F\n",
    "TEST_TBR_F = TEST_THE_F / TEST_BE_F\n",
    "\n",
    "TEST_AOR_F = TEST_ALP_F / TEST_ORI_F\n",
    "TEST_ABR_F = TEST_ALP_F / TEST_BE_F\n",
    "\n",
    "TEST_BOR_F = TEST_BE_F / TEST_ORI_F\n",
    "\n",
    "\n",
    "temp1 = pd.concat([TEST_ORI_F,TEST_DEL_F,TEST_THE_F,TEST_ALP_F,TEST_BE_F,\n",
    "                   TEST_DOR_F,TEST_DTR_F,TEST_DAR_F,TEST_DBR_F,\n",
    "                   TEST_TOR_F,TEST_TAR_F,TEST_TBR_F,\n",
    "                   TEST_AOR_F,TEST_ABR_F,\n",
    "                   TEST_BOR_F\n",
    "                  ],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to Feature_MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "RR =  pd.DataFrame(temp0.values)\n",
    "TT =  pd.DataFrame(temp1.values)\n",
    "RR.to_csv('./REST_Feature_MAP_24_f12&b15.csv',index = False)\n",
    "TT.to_csv('./TEST_Feature_MAP_24_f12&b15.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
